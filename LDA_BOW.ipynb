{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9b78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models import LdaMulticore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea88369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04de4783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1018c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    lauren boebert calling abolishment dept educat...\n",
       "1    wish had read seen post last week bought ascor...\n",
       "2    its covid amoxicillin will not work pretty sur...\n",
       "3    alarm got coincidentally i have just started a...\n",
       "4    #beantibioticsaware it is #antibioticawareness...\n",
       "Name: New Tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('Drugs.xlsx')['New Tweet']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c1b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import en_core_web_sm\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a7769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'dept', 'education', 'chlamydia', 'speak', 'danger']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "print(data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8565463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4859fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 call\n",
      "1 chlamydia\n",
      "2 danger\n",
      "3 dept\n",
      "4 education\n",
      "5 speak\n",
      "6 always\n",
      "7 amoxiclave\n",
      "8 ascorbic\n",
      "9 buy\n",
      "10 cough\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753896e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "# words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71eb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 20 (\"doctor\") appears 1 time.\n",
      "Word 28 (\"get\") appears 1 time.\n",
      "Word 55 (\"take\") appears 1 time.\n",
      "Word 70 (\"right\") appears 1 time.\n",
      "Word 162 (\"cefexime\") appears 1 time.\n",
      "Word 163 (\"fever\") appears 1 time.\n",
      "Word 164 (\"late\") appears 1 time.\n",
      "Word 165 (\"prescribed\") appears 1 time.\n",
      "Word 166 (\"relief\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09b9b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"call\") appears 1 time.\n",
      "Document 0: Word 1 (\"chlamydia\") appears 1 time.\n",
      "Document 0: Word 2 (\"danger\") appears 1 time.\n",
      "Document 0: Word 3 (\"dept\") appears 1 time.\n",
      "Document 0: Word 4 (\"education\") appears 1 time.\n",
      "Document 0: Word 5 (\"speak\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 6 (\"always\") appears 1 time.\n",
      "Document 1: Word 7 (\"amoxiclave\") appears 1 time.\n",
      "Document 1: Word 8 (\"ascorbic\") appears 1 time.\n",
      "Document 1: Word 9 (\"buy\") appears 1 time.\n",
      "Document 1: Word 10 (\"cough\") appears 1 time.\n",
      "Document 1: Word 11 (\"last\") appears 1 time.\n",
      "Document 1: Word 12 (\"post\") appears 1 time.\n",
      "Document 1: Word 13 (\"read\") appears 1 time.\n",
      "Document 1: Word 14 (\"see\") appears 1 time.\n",
      "Document 1: Word 15 (\"syrup\") appears 1 time.\n",
      "Document 1: Word 16 (\"time\") appears 1 time.\n",
      "Document 1: Word 17 (\"week\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 2: Word 19 (\"covid\") appears 2 time.\n",
      "Document 2: Word 20 (\"doctor\") appears 1 time.\n",
      "Document 2: Word 21 (\"prescribe\") appears 1 time.\n",
      "Document 2: Word 22 (\"pretty\") appears 1 time.\n",
      "Document 2: Word 23 (\"sure\") appears 1 time.\n",
      "Document 2: Word 24 (\"think\") appears 1 time.\n",
      "Document 2: Word 25 (\"work\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 26 (\"alarm\") appears 1 time.\n",
      "Document 3: Word 27 (\"coincidentally\") appears 1 time.\n",
      "Document 3: Word 28 (\"get\") appears 1 time.\n",
      "Document 3: Word 29 (\"just\") appears 1 time.\n",
      "Document 3: Word 30 (\"so\") appears 1 time.\n",
      "Document 3: Word 31 (\"start\") appears 1 time.\n",
      "Document 3: Word 32 (\"today\") appears 1 time.\n",
      "Document 3: Word 33 (\"useful\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 4: Word 34 (\"antibiotic\") appears 1 time.\n",
      "Document 4: Word 35 (\"good\") appears 1 time.\n",
      "Document 4: Word 36 (\"match\") appears 1 time.\n",
      "Document 4: Word 37 (\"personality\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 14 (\"see\") appears 1 time.\n",
      "Document 5: Word 16 (\"time\") appears 1 time.\n",
      "Document 5: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 5: Word 20 (\"doctor\") appears 1 time.\n",
      "Document 5: Word 38 (\"again\") appears 2 time.\n",
      "Document 5: Word 39 (\"chest\") appears 1 time.\n",
      "Document 5: Word 40 (\"definite\") appears 1 time.\n",
      "Document 5: Word 41 (\"drs\") appears 1 time.\n",
      "Document 5: Word 42 (\"give\") appears 1 time.\n",
      "Document 5: Word 43 (\"happen\") appears 1 time.\n",
      "Document 5: Word 44 (\"hear\") appears 1 time.\n",
      "Document 5: Word 45 (\"infection\") appears 1 time.\n",
      "Document 5: Word 46 (\"likely\") appears 1 time.\n",
      "Document 5: Word 47 (\"most\") appears 1 time.\n",
      "Document 5: Word 48 (\"normal\") appears 1 time.\n",
      "Document 5: Word 49 (\"ongoing\") appears 1 time.\n",
      "Document 5: Word 50 (\"pocket\") appears 1 time.\n",
      "Document 5: Word 51 (\"rattle\") appears 1 time.\n",
      "Document 5: Word 52 (\"reply\") appears 1 time.\n",
      "Document 5: Word 53 (\"say\") appears 1 time.\n",
      "Document 5: Word 54 (\"straight\") appears 1 time.\n",
      "Document 5: Word 55 (\"take\") appears 2 time.\n",
      "\n",
      "\n",
      "Document 6: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 6: Word 56 (\"allergic\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 7: Word 24 (\"think\") appears 1 time.\n",
      "Document 7: Word 34 (\"antibiotic\") appears 1 time.\n",
      "Document 7: Word 57 (\"indeed\") appears 1 time.\n",
      "Document 7: Word 58 (\"like\") appears 1 time.\n",
      "Document 7: Word 59 (\"other\") appears 1 time.\n",
      "Document 7: Word 60 (\"seem\") appears 1 time.\n",
      "Document 7: Word 61 (\"taste\") appears 2 time.\n",
      "Document 7: Word 62 (\"weird\") appears 1 time.\n",
      "Document 7: Word 63 (\"well\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 8: Word 64 (\"drawer\") appears 1 time.\n",
      "Document 8: Word 65 (\"find\") appears 1 time.\n",
      "Document 8: Word 66 (\"hurt\") appears 1 time.\n",
      "Document 8: Word 67 (\"kind\") appears 1 time.\n",
      "Document 8: Word 68 (\"med\") appears 1 time.\n",
      "Document 8: Word 69 (\"odd\") appears 1 time.\n",
      "Document 8: Word 70 (\"right\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 9: Word 45 (\"infection\") appears 1 time.\n",
      "Document 9: Word 71 (\"anti\") appears 1 time.\n",
      "Document 9: Word 72 (\"budesinine\") appears 1 time.\n",
      "Document 9: Word 73 (\"corticosteroid\") appears 1 time.\n",
      "Document 9: Word 74 (\"cult\") appears 1 time.\n",
      "Document 9: Word 75 (\"curceritin\") appears 1 time.\n",
      "Document 9: Word 76 (\"dose\") appears 1 time.\n",
      "Document 9: Word 77 (\"fool\") appears 1 time.\n",
      "Document 9: Word 78 (\"high\") appears 1 time.\n",
      "Document 9: Word 79 (\"hundred\") appears 1 time.\n",
      "Document 9: Word 80 (\"hydroxy\") appears 1 time.\n",
      "Document 9: Word 81 (\"inflammatory\") appears 1 time.\n",
      "Document 9: Word 82 (\"lung\") appears 1 time.\n",
      "Document 9: Word 83 (\"protocol\") appears 1 time.\n",
      "Document 9: Word 84 (\"push\") appears 1 time.\n",
      "Document 9: Word 85 (\"save\") appears 1 time.\n",
      "Document 9: Word 86 (\"secondary\") appears 1 time.\n",
      "Document 9: Word 87 (\"trump\") appears 1 time.\n",
      "Document 9: Word 88 (\"zinc\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], dictionary[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56f1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1536a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.018*\"amoxicillin\" + 0.014*\"get\" + 0.012*\"lorazepam\" + 0.009*\"infection\" + 0.009*\"week\" + 0.009*\"say\" + 0.008*\"give\" + 0.008*\"pain\" + 0.008*\"prescription\" + 0.007*\"antibiotic\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.016*\"take\" + 0.011*\"amoxicillin\" + 0.011*\"use\" + 0.011*\"patient\" + 0.008*\"give\" + 0.007*\"short\" + 0.007*\"help\" + 0.007*\"link\" + 0.006*\"lorazepam\" + 0.006*\"get\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.024*\"take\" + 0.022*\"amoxicillin\" + 0.015*\"get\" + 0.012*\"lorazepam\" + 0.012*\"make\" + 0.010*\"go\" + 0.009*\"work\" + 0.008*\"nurofen\" + 0.008*\"so\" + 0.007*\"time\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.024*\"amoxicillin\" + 0.014*\"get\" + 0.011*\"go\" + 0.010*\"use\" + 0.010*\"take\" + 0.009*\"lorazepam\" + 0.009*\"infection\" + 0.009*\"give\" + 0.008*\"antibiotic\" + 0.007*\"tooth\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.052*\"lorazepam\" + 0.018*\"take\" + 0.013*\"just\" + 0.012*\"get\" + 0.010*\"so\" + 0.010*\"need\" + 0.010*\"say\" + 0.008*\"sleep\" + 0.008*\"cancer\" + 0.007*\"doctor\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf617b6a",
   "metadata": {},
   "source": [
    "### Amoxicillin LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "199ec754",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data = pd.read_excel('Amoxicillin.xlsx')['New Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391cda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call dept education chlamydia speak danger\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(am_data)\n",
    "print(lemmatized_texts[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f503dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'dept', 'education', 'chlamydia', 'speak', 'danger']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "am_data_words = gen_words(lemmatized_texts)\n",
    "print(am_data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd8a66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "am_dict = gensim.corpora.Dictionary(am_data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "313db1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 call\n",
      "1 chlamydia\n",
      "2 danger\n",
      "3 dept\n",
      "4 education\n",
      "5 speak\n",
      "6 always\n",
      "7 amoxiclave\n",
      "8 ascorbic\n",
      "9 buy\n",
      "10 cough\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in am_dict.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ac74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [am_dict.doc2bow(doc) for doc in am_data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e033ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 20 (\"doctor\") appears 1 time.\n",
      "Word 28 (\"get\") appears 1 time.\n",
      "Word 55 (\"take\") appears 1 time.\n",
      "Word 70 (\"right\") appears 1 time.\n",
      "Word 162 (\"cefexime\") appears 1 time.\n",
      "Word 163 (\"fever\") appears 1 time.\n",
      "Word 164 (\"late\") appears 1 time.\n",
      "Word 165 (\"prescribed\") appears 1 time.\n",
      "Word 166 (\"relief\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     am_dict[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da7cb0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"call\") appears 1 time.\n",
      "Document 0: Word 1 (\"chlamydia\") appears 1 time.\n",
      "Document 0: Word 2 (\"danger\") appears 1 time.\n",
      "Document 0: Word 3 (\"dept\") appears 1 time.\n",
      "Document 0: Word 4 (\"education\") appears 1 time.\n",
      "Document 0: Word 5 (\"speak\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 6 (\"always\") appears 1 time.\n",
      "Document 1: Word 7 (\"amoxiclave\") appears 1 time.\n",
      "Document 1: Word 8 (\"ascorbic\") appears 1 time.\n",
      "Document 1: Word 9 (\"buy\") appears 1 time.\n",
      "Document 1: Word 10 (\"cough\") appears 1 time.\n",
      "Document 1: Word 11 (\"last\") appears 1 time.\n",
      "Document 1: Word 12 (\"post\") appears 1 time.\n",
      "Document 1: Word 13 (\"read\") appears 1 time.\n",
      "Document 1: Word 14 (\"see\") appears 1 time.\n",
      "Document 1: Word 15 (\"syrup\") appears 1 time.\n",
      "Document 1: Word 16 (\"time\") appears 1 time.\n",
      "Document 1: Word 17 (\"week\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 2: Word 19 (\"covid\") appears 2 time.\n",
      "Document 2: Word 20 (\"doctor\") appears 1 time.\n",
      "Document 2: Word 21 (\"prescribe\") appears 1 time.\n",
      "Document 2: Word 22 (\"pretty\") appears 1 time.\n",
      "Document 2: Word 23 (\"sure\") appears 1 time.\n",
      "Document 2: Word 24 (\"think\") appears 1 time.\n",
      "Document 2: Word 25 (\"work\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 26 (\"alarm\") appears 1 time.\n",
      "Document 3: Word 27 (\"coincidentally\") appears 1 time.\n",
      "Document 3: Word 28 (\"get\") appears 1 time.\n",
      "Document 3: Word 29 (\"just\") appears 1 time.\n",
      "Document 3: Word 30 (\"so\") appears 1 time.\n",
      "Document 3: Word 31 (\"start\") appears 1 time.\n",
      "Document 3: Word 32 (\"today\") appears 1 time.\n",
      "Document 3: Word 33 (\"useful\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 4: Word 34 (\"antibiotic\") appears 1 time.\n",
      "Document 4: Word 35 (\"good\") appears 1 time.\n",
      "Document 4: Word 36 (\"match\") appears 1 time.\n",
      "Document 4: Word 37 (\"personality\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 14 (\"see\") appears 1 time.\n",
      "Document 5: Word 16 (\"time\") appears 1 time.\n",
      "Document 5: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 5: Word 20 (\"doctor\") appears 1 time.\n",
      "Document 5: Word 38 (\"again\") appears 2 time.\n",
      "Document 5: Word 39 (\"chest\") appears 1 time.\n",
      "Document 5: Word 40 (\"definite\") appears 1 time.\n",
      "Document 5: Word 41 (\"drs\") appears 1 time.\n",
      "Document 5: Word 42 (\"give\") appears 1 time.\n",
      "Document 5: Word 43 (\"happen\") appears 1 time.\n",
      "Document 5: Word 44 (\"hear\") appears 1 time.\n",
      "Document 5: Word 45 (\"infection\") appears 1 time.\n",
      "Document 5: Word 46 (\"likely\") appears 1 time.\n",
      "Document 5: Word 47 (\"most\") appears 1 time.\n",
      "Document 5: Word 48 (\"normal\") appears 1 time.\n",
      "Document 5: Word 49 (\"ongoing\") appears 1 time.\n",
      "Document 5: Word 50 (\"pocket\") appears 1 time.\n",
      "Document 5: Word 51 (\"rattle\") appears 1 time.\n",
      "Document 5: Word 52 (\"reply\") appears 1 time.\n",
      "Document 5: Word 53 (\"say\") appears 1 time.\n",
      "Document 5: Word 54 (\"straight\") appears 1 time.\n",
      "Document 5: Word 55 (\"take\") appears 2 time.\n",
      "\n",
      "\n",
      "Document 6: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 6: Word 56 (\"allergic\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 7: Word 24 (\"think\") appears 1 time.\n",
      "Document 7: Word 34 (\"antibiotic\") appears 1 time.\n",
      "Document 7: Word 57 (\"indeed\") appears 1 time.\n",
      "Document 7: Word 58 (\"like\") appears 1 time.\n",
      "Document 7: Word 59 (\"other\") appears 1 time.\n",
      "Document 7: Word 60 (\"seem\") appears 1 time.\n",
      "Document 7: Word 61 (\"taste\") appears 2 time.\n",
      "Document 7: Word 62 (\"weird\") appears 1 time.\n",
      "Document 7: Word 63 (\"well\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 8: Word 64 (\"drawer\") appears 1 time.\n",
      "Document 8: Word 65 (\"find\") appears 1 time.\n",
      "Document 8: Word 66 (\"hurt\") appears 1 time.\n",
      "Document 8: Word 67 (\"kind\") appears 1 time.\n",
      "Document 8: Word 68 (\"med\") appears 1 time.\n",
      "Document 8: Word 69 (\"odd\") appears 1 time.\n",
      "Document 8: Word 70 (\"right\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 9: Word 45 (\"infection\") appears 1 time.\n",
      "Document 9: Word 71 (\"anti\") appears 1 time.\n",
      "Document 9: Word 72 (\"budesinine\") appears 1 time.\n",
      "Document 9: Word 73 (\"corticosteroid\") appears 1 time.\n",
      "Document 9: Word 74 (\"cult\") appears 1 time.\n",
      "Document 9: Word 75 (\"curceritin\") appears 1 time.\n",
      "Document 9: Word 76 (\"dose\") appears 1 time.\n",
      "Document 9: Word 77 (\"fool\") appears 1 time.\n",
      "Document 9: Word 78 (\"high\") appears 1 time.\n",
      "Document 9: Word 79 (\"hundred\") appears 1 time.\n",
      "Document 9: Word 80 (\"hydroxy\") appears 1 time.\n",
      "Document 9: Word 81 (\"inflammatory\") appears 1 time.\n",
      "Document 9: Word 82 (\"lung\") appears 1 time.\n",
      "Document 9: Word 83 (\"protocol\") appears 1 time.\n",
      "Document 9: Word 84 (\"push\") appears 1 time.\n",
      "Document 9: Word 85 (\"save\") appears 1 time.\n",
      "Document 9: Word 86 (\"secondary\") appears 1 time.\n",
      "Document 9: Word 87 (\"trump\") appears 1 time.\n",
      "Document 9: Word 88 (\"zinc\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], am_dict[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ef0534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = am_dict,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20cc5ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.021*\"amoxicillin\" + 0.017*\"get\" + 0.016*\"infection\" + 0.015*\"go\" + 0.012*\"right\" + 0.010*\"take\" + 0.009*\"antibiotic\" + 0.008*\"treatment\" + 0.007*\"week\" + 0.007*\"day\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.042*\"amoxicillin\" + 0.016*\"antibiotic\" + 0.016*\"infection\" + 0.015*\"get\" + 0.013*\"use\" + 0.011*\"give\" + 0.008*\"start\" + 0.007*\"take\" + 0.007*\"back\" + 0.007*\"strep\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.013*\"amoxicillin\" + 0.013*\"get\" + 0.011*\"use\" + 0.011*\"drug\" + 0.007*\"work\" + 0.007*\"antibiotic\" + 0.007*\"go\" + 0.007*\"prophylaxis\" + 0.006*\"think\" + 0.006*\"take\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.042*\"amoxicillin\" + 0.026*\"get\" + 0.015*\"give\" + 0.011*\"day\" + 0.009*\"now\" + 0.009*\"go\" + 0.008*\"medicine\" + 0.007*\"say\" + 0.006*\"week\" + 0.005*\"take\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.025*\"amoxicillin\" + 0.019*\"take\" + 0.012*\"prescribe\" + 0.010*\"week\" + 0.009*\"still\" + 0.008*\"make\" + 0.008*\"infection\" + 0.007*\"say\" + 0.007*\"know\" + 0.007*\"tooth\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacfa31",
   "metadata": {},
   "source": [
    "### Nurofen LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc28f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_data = pd.read_excel('Nurofen.xlsx')['New Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3ce4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look box nurofen take too many\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(nu_data)\n",
    "print(lemmatized_texts[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b08f42cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['look', 'box', 'nurofen', 'take', 'too', 'many']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "nu_data_words = gen_words(lemmatized_texts)\n",
    "print(nu_data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "786562a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "nu_dict = gensim.corpora.Dictionary(nu_data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2745d828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 box\n",
      "1 look\n",
      "2 many\n",
      "3 nurofen\n",
      "4 take\n",
      "5 too\n",
      "6 offer\n",
      "7 tell\n",
      "8 else\n",
      "9 give\n",
      "10 only\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in nu_dict.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adc34f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [nu_dict.doc2bow(doc) for doc in nu_data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1cb4bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 107 (\"time\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     nu_dict[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db34b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"box\") appears 1 time.\n",
      "Document 0: Word 1 (\"look\") appears 1 time.\n",
      "Document 0: Word 2 (\"many\") appears 1 time.\n",
      "Document 0: Word 3 (\"nurofen\") appears 1 time.\n",
      "Document 0: Word 4 (\"take\") appears 1 time.\n",
      "Document 0: Word 5 (\"too\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 3 (\"nurofen\") appears 1 time.\n",
      "Document 1: Word 4 (\"take\") appears 1 time.\n",
      "Document 1: Word 6 (\"offer\") appears 1 time.\n",
      "Document 1: Word 7 (\"tell\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 3 (\"nurofen\") appears 1 time.\n",
      "Document 2: Word 4 (\"take\") appears 1 time.\n",
      "Document 2: Word 8 (\"else\") appears 1 time.\n",
      "Document 2: Word 9 (\"give\") appears 1 time.\n",
      "Document 2: Word 10 (\"only\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 1 (\"look\") appears 3 time.\n",
      "Document 3: Word 11 (\"capsule\") appears 1 time.\n",
      "Document 3: Word 12 (\"entrance\") appears 1 time.\n",
      "Document 3: Word 13 (\"especially\") appears 1 time.\n",
      "Document 3: Word 14 (\"full\") appears 1 time.\n",
      "Document 3: Word 15 (\"imagine\") appears 1 time.\n",
      "Document 3: Word 16 (\"just\") appears 1 time.\n",
      "Document 3: Word 17 (\"people\") appears 1 time.\n",
      "Document 3: Word 18 (\"port\") appears 1 time.\n",
      "Document 3: Word 19 (\"spaceship\") appears 1 time.\n",
      "Document 3: Word 20 (\"teen\") appears 1 time.\n",
      "Document 3: Word 21 (\"tiny\") appears 1 time.\n",
      "Document 3: Word 22 (\"used\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 23 (\"already\") appears 1 time.\n",
      "Document 4: Word 24 (\"covid\") appears 1 time.\n",
      "Document 4: Word 25 (\"handle\") appears 1 time.\n",
      "Document 4: Word 26 (\"help\") appears 1 time.\n",
      "Document 4: Word 27 (\"inflammation\") appears 1 time.\n",
      "Document 4: Word 28 (\"nastie\") appears 1 time.\n",
      "Document 4: Word 29 (\"panadol\") appears 1 time.\n",
      "Document 4: Word 30 (\"post\") appears 1 time.\n",
      "Document 4: Word 31 (\"sleep\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 3 (\"nurofen\") appears 1 time.\n",
      "Document 5: Word 4 (\"take\") appears 2 time.\n",
      "Document 5: Word 7 (\"tell\") appears 1 time.\n",
      "Document 5: Word 17 (\"people\") appears 1 time.\n",
      "Document 5: Word 26 (\"help\") appears 1 time.\n",
      "Document 5: Word 29 (\"panadol\") appears 1 time.\n",
      "Document 5: Word 32 (\"anti\") appears 1 time.\n",
      "Document 5: Word 33 (\"bit\") appears 1 time.\n",
      "Document 5: Word 34 (\"bulge\") appears 1 time.\n",
      "Document 5: Word 35 (\"disc\") appears 1 time.\n",
      "Document 5: Word 36 (\"feel\") appears 1 time.\n",
      "Document 5: Word 37 (\"good\") appears 1 time.\n",
      "Document 5: Word 38 (\"inflammatory\") appears 1 time.\n",
      "Document 5: Word 39 (\"most\") appears 1 time.\n",
      "Document 5: Word 40 (\"ok\") appears 1 time.\n",
      "Document 5: Word 41 (\"short\") appears 1 time.\n",
      "Document 5: Word 42 (\"term\") appears 1 time.\n",
      "Document 5: Word 43 (\"well\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 6: Word 44 (\"contain\") appears 1 time.\n",
      "Document 6: Word 45 (\"show\") appears 1 time.\n",
      "Document 6: Word 46 (\"tablet\") appears 1 time.\n",
      "Document 6: Word 47 (\"test\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 7: Word 3 (\"nurofen\") appears 1 time.\n",
      "Document 7: Word 8 (\"else\") appears 1 time.\n",
      "Document 7: Word 48 (\"acknowledge\") appears 1 time.\n",
      "Document 7: Word 49 (\"always\") appears 1 time.\n",
      "Document 7: Word 50 (\"biscuit\") appears 1 time.\n",
      "Document 7: Word 51 (\"cough\") appears 1 time.\n",
      "Document 7: Word 52 (\"drink\") appears 1 time.\n",
      "Document 7: Word 53 (\"drop\") appears 1 time.\n",
      "Document 7: Word 54 (\"get\") appears 3 time.\n",
      "Document 7: Word 55 (\"grateful\") appears 1 time.\n",
      "Document 7: Word 56 (\"guy\") appears 1 time.\n",
      "Document 7: Word 57 (\"later\") appears 1 time.\n",
      "Document 7: Word 58 (\"need\") appears 1 time.\n",
      "Document 7: Word 59 (\"raise\") appears 1 time.\n",
      "Document 7: Word 60 (\"say\") appears 4 time.\n",
      "Document 7: Word 61 (\"so\") appears 2 time.\n",
      "Document 7: Word 62 (\"sushi\") appears 1 time.\n",
      "Document 7: Word 63 (\"try\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 3 (\"nurofen\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 9: Word 16 (\"just\") appears 1 time.\n",
      "Document 9: Word 64 (\"register\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], nu_dict[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21da9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = nu_dict,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b580def5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.033*\"nurofen\" + 0.023*\"just\" + 0.022*\"get\" + 0.018*\"take\" + 0.018*\"use\" + 0.018*\"night\" + 0.012*\"too\" + 0.012*\"couple\" + 0.012*\"feel\" + 0.012*\"child\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.042*\"take\" + 0.026*\"nurofen\" + 0.018*\"tell\" + 0.018*\"many\" + 0.018*\"make\" + 0.018*\"good\" + 0.018*\"help\" + 0.018*\"time\" + 0.010*\"pain\" + 0.010*\"thank\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.022*\"take\" + 0.022*\"say\" + 0.022*\"nurofen\" + 0.017*\"bad\" + 0.017*\"help\" + 0.011*\"give\" + 0.011*\"just\" + 0.011*\"go\" + 0.011*\"good\" + 0.011*\"panadol\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.028*\"nurofen\" + 0.028*\"look\" + 0.021*\"just\" + 0.021*\"pain\" + 0.015*\"head\" + 0.015*\"give\" + 0.015*\"so\" + 0.008*\"open\" + 0.008*\"people\" + 0.008*\"full\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.053*\"nurofen\" + 0.024*\"say\" + 0.019*\"so\" + 0.016*\"get\" + 0.015*\"pain\" + 0.010*\"day\" + 0.010*\"really\" + 0.010*\"same\" + 0.010*\"now\" + 0.010*\"buy\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a5e7f",
   "metadata": {},
   "source": [
    "### Lorazepam LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79c94f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_data = pd.read_excel('Lorazepam.xlsx')['New Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "653a8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lorazepam stimulate il6 production associate poor survival outcome pancreatic cancer clinical cancer\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(lo_data)\n",
    "print(lemmatized_texts[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c03e4be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorazepam', 'stimulate', 'il', 'production', 'associate', 'poor', 'survival', 'outcome', 'pancreatic', 'cancer', 'clinical', 'cancer', 'research', 'cancer', 'research']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "lo_data_words = gen_words(lemmatized_texts)\n",
    "print(lo_data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba5e1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "lo_dict = gensim.corpora.Dictionary(lo_data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5243242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 associate\n",
      "1 cancer\n",
      "2 clinical\n",
      "3 il\n",
      "4 lorazepam\n",
      "5 outcome\n",
      "6 pancreatic\n",
      "7 poor\n",
      "8 production\n",
      "9 research\n",
      "10 stimulate\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in lo_dict.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dc31e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [lo_dict.doc2bow(doc) for doc in lo_data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6e52bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 4 (\"lorazepam\") appears 1 time.\n",
      "Word 34 (\"make\") appears 2 time.\n",
      "Word 45 (\"take\") appears 1 time.\n",
      "Word 53 (\"go\") appears 1 time.\n",
      "Word 68 (\"really\") appears 1 time.\n",
      "Word 80 (\"possible\") appears 1 time.\n",
      "Word 152 (\"today\") appears 1 time.\n",
      "Word 156 (\"search\") appears 1 time.\n",
      "Word 157 (\"able\") appears 1 time.\n",
      "Word 158 (\"appt\") appears 2 time.\n",
      "Word 159 (\"dose\") appears 1 time.\n",
      "Word 160 (\"find\") appears 2 time.\n",
      "Word 161 (\"foot\") appears 1 time.\n",
      "Word 162 (\"hard\") appears 1 time.\n",
      "Word 163 (\"hope\") appears 1 time.\n",
      "Word 164 (\"injure\") appears 1 time.\n",
      "Word 165 (\"keep\") appears 1 time.\n",
      "Word 166 (\"oxy\") appears 1 time.\n",
      "Word 167 (\"shelf\") appears 1 time.\n",
      "Word 168 (\"still\") appears 2 time.\n",
      "Word 169 (\"thank\") appears 1 time.\n",
      "Word 170 (\"tomorrow\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     lo_dict[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fca6eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"associate\") appears 1 time.\n",
      "Document 0: Word 1 (\"cancer\") appears 3 time.\n",
      "Document 0: Word 2 (\"clinical\") appears 1 time.\n",
      "Document 0: Word 3 (\"il\") appears 1 time.\n",
      "Document 0: Word 4 (\"lorazepam\") appears 1 time.\n",
      "Document 0: Word 5 (\"outcome\") appears 1 time.\n",
      "Document 0: Word 6 (\"pancreatic\") appears 1 time.\n",
      "Document 0: Word 7 (\"poor\") appears 1 time.\n",
      "Document 0: Word 8 (\"production\") appears 1 time.\n",
      "Document 0: Word 9 (\"research\") appears 2 time.\n",
      "Document 0: Word 10 (\"stimulate\") appears 1 time.\n",
      "Document 0: Word 11 (\"survival\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 12 (\"buy\") appears 1 time.\n",
      "Document 1: Word 13 (\"discount\") appears 1 time.\n",
      "Document 1: Word 14 (\"huge\") appears 1 time.\n",
      "Document 1: Word 15 (\"low\") appears 1 time.\n",
      "Document 1: Word 16 (\"online\") appears 1 time.\n",
      "Document 1: Word 17 (\"pharmacy\") appears 1 time.\n",
      "Document 1: Word 18 (\"prescription\") appears 2 time.\n",
      "Document 1: Word 19 (\"price\") appears 1 time.\n",
      "Document 1: Word 20 (\"trust\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 21 (\"about\") appears 1 time.\n",
      "Document 2: Word 22 (\"amazingly\") appears 1 time.\n",
      "Document 2: Word 23 (\"combination\") appears 1 time.\n",
      "Document 2: Word 24 (\"conference\") appears 1 time.\n",
      "Document 2: Word 25 (\"day\") appears 1 time.\n",
      "Document 2: Word 26 (\"dr\") appears 1 time.\n",
      "Document 2: Word 27 (\"effect\") appears 1 time.\n",
      "Document 2: Word 28 (\"effective\") appears 1 time.\n",
      "Document 2: Word 29 (\"flight\") appears 1 time.\n",
      "Document 2: Word 30 (\"great\") appears 1 time.\n",
      "Document 2: Word 31 (\"hour\") appears 1 time.\n",
      "Document 2: Word 32 (\"learn\") appears 1 time.\n",
      "Document 2: Word 33 (\"loopy\") appears 1 time.\n",
      "Document 2: Word 34 (\"make\") appears 1 time.\n",
      "Document 2: Word 35 (\"many\") appears 1 time.\n",
      "Document 2: Word 36 (\"people\") appears 1 time.\n",
      "Document 2: Word 37 (\"propranolol\") appears 1 time.\n",
      "Document 2: Word 38 (\"rest\") appears 1 time.\n",
      "Document 2: Word 39 (\"similar\") appears 1 time.\n",
      "Document 2: Word 40 (\"travel\") appears 1 time.\n",
      "Document 2: Word 41 (\"use\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 4 (\"lorazepam\") appears 1 time.\n",
      "Document 3: Word 42 (\"art\") appears 1 time.\n",
      "Document 3: Word 43 (\"bed\") appears 1 time.\n",
      "Document 3: Word 44 (\"restoration\") appears 1 time.\n",
      "Document 3: Word 45 (\"take\") appears 1 time.\n",
      "Document 3: Word 46 (\"time\") appears 1 time.\n",
      "Document 3: Word 47 (\"video\") appears 1 time.\n",
      "Document 3: Word 48 (\"watch\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 4 (\"lorazepam\") appears 2 time.\n",
      "Document 4: Word 31 (\"hour\") appears 2 time.\n",
      "Document 4: Word 39 (\"similar\") appears 1 time.\n",
      "Document 4: Word 49 (\"acting\") appears 1 time.\n",
      "Document 4: Word 50 (\"diazepam\") appears 2 time.\n",
      "Document 4: Word 51 (\"equivalent\") appears 1 time.\n",
      "Document 4: Word 52 (\"fast\") appears 1 time.\n",
      "Document 4: Word 53 (\"go\") appears 1 time.\n",
      "Document 4: Word 54 (\"likely\") appears 1 time.\n",
      "Document 4: Word 55 (\"mean\") appears 1 time.\n",
      "Document 4: Word 56 (\"most\") appears 1 time.\n",
      "Document 4: Word 57 (\"safe\") appears 1 time.\n",
      "Document 4: Word 58 (\"say\") appears 1 time.\n",
      "Document 4: Word 59 (\"situation\") appears 1 time.\n",
      "Document 4: Word 60 (\"sorry\") appears 1 time.\n",
      "Document 4: Word 61 (\"stay\") appears 2 time.\n",
      "Document 4: Word 62 (\"system\") appears 1 time.\n",
      "Document 4: Word 63 (\"week\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 4 (\"lorazepam\") appears 1 time.\n",
      "Document 5: Word 31 (\"hour\") appears 1 time.\n",
      "Document 5: Word 64 (\"awake\") appears 1 time.\n",
      "Document 5: Word 65 (\"fuck\") appears 1 time.\n",
      "Document 5: Word 66 (\"knock\") appears 1 time.\n",
      "Document 5: Word 67 (\"perfect\") appears 1 time.\n",
      "Document 5: Word 68 (\"really\") appears 1 time.\n",
      "Document 5: Word 69 (\"sleep\") appears 1 time.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Document 7: Word 4 (\"lorazepam\") appears 2 time.\n",
      "Document 7: Word 50 (\"diazepam\") appears 2 time.\n",
      "Document 7: Word 70 (\"actually\") appears 1 time.\n",
      "Document 7: Word 71 (\"cause\") appears 1 time.\n",
      "Document 7: Word 72 (\"doctor\") appears 1 time.\n",
      "Document 7: Word 73 (\"exactly\") appears 1 time.\n",
      "Document 7: Word 74 (\"explain\") appears 1 time.\n",
      "Document 7: Word 75 (\"feel\") appears 1 time.\n",
      "Document 7: Word 76 (\"get\") appears 1 time.\n",
      "Document 7: Word 77 (\"happen\") appears 2 time.\n",
      "Document 7: Word 78 (\"harm\") appears 1 time.\n",
      "Document 7: Word 79 (\"head\") appears 1 time.\n",
      "Document 7: Word 80 (\"possible\") appears 1 time.\n",
      "Document 7: Word 81 (\"real\") appears 1 time.\n",
      "Document 7: Word 82 (\"same\") appears 1 time.\n",
      "Document 7: Word 83 (\"tonight\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 4 (\"lorazepam\") appears 1 time.\n",
      "Document 8: Word 28 (\"effective\") appears 1 time.\n",
      "Document 8: Word 84 (\"believe\") appears 1 time.\n",
      "Document 8: Word 85 (\"midazolam\") appears 1 time.\n",
      "Document 8: Word 86 (\"more\") appears 1 time.\n",
      "Document 8: Word 87 (\"think\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 9: Word 4 (\"lorazepam\") appears 1 time.\n",
      "Document 9: Word 45 (\"take\") appears 1 time.\n",
      "Document 9: Word 46 (\"time\") appears 1 time.\n",
      "Document 9: Word 88 (\"blanket\") appears 1 time.\n",
      "Document 9: Word 89 (\"wrap\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], lo_dict[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad4f14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = lo_dict,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d9df8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.046*\"lorazepam\" + 0.042*\"take\" + 0.014*\"help\" + 0.010*\"think\" + 0.006*\"find\" + 0.006*\"hour\" + 0.006*\"say\" + 0.006*\"sleep\" + 0.006*\"get\" + 0.006*\"experience\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.038*\"lorazepam\" + 0.019*\"give\" + 0.012*\"dose\" + 0.011*\"anxiety\" + 0.011*\"go\" + 0.010*\"take\" + 0.010*\"sleep\" + 0.010*\"find\" + 0.009*\"treatment\" + 0.008*\"make\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.035*\"lorazepam\" + 0.025*\"take\" + 0.024*\"work\" + 0.020*\"make\" + 0.019*\"so\" + 0.013*\"too\" + 0.012*\"say\" + 0.012*\"just\" + 0.011*\"get\" + 0.009*\"go\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.070*\"lorazepam\" + 0.017*\"need\" + 0.011*\"get\" + 0.011*\"drug\" + 0.011*\"take\" + 0.010*\"give\" + 0.009*\"just\" + 0.008*\"use\" + 0.007*\"cause\" + 0.007*\"sleep\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.049*\"lorazepam\" + 0.030*\"cancer\" + 0.030*\"patient\" + 0.019*\"survival\" + 0.019*\"pancreatic\" + 0.017*\"outcome\" + 0.015*\"link\" + 0.013*\"associate\" + 0.012*\"benzodiazepine\" + 0.011*\"so\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb78679",
   "metadata": {},
   "source": [
    "### Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a756fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>New Tweet</th>\n",
       "      <th>Word Count.1</th>\n",
       "      <th>Location</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1030000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 09:09:19+00:00</td>\n",
       "      <td>@bearish0411 if its COVID, amoxicillin will no...</td>\n",
       "      <td>23</td>\n",
       "      <td>its covid amoxicillin will not work pretty sur...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.375</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2245928095</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 09:09:16+00:00</td>\n",
       "      <td>@missmulrooney alarm. got it. coincidentally, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>alarm got coincidentally i have just started a...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1590000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 08:47:58+00:00</td>\n",
       "      <td>RT @skdembe: #BeAntibioticsAware... It's #Anti...</td>\n",
       "      <td>15</td>\n",
       "      <td>#beantibioticsaware it is #antibioticawareness...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>388774547</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 08:47:22+00:00</td>\n",
       "      <td>''took her straight to drs AGAIN where the doc...</td>\n",
       "      <td>49</td>\n",
       "      <td>took straight drs again where doctor time says...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>830271474</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 05:23:58+00:00</td>\n",
       "      <td>I do have a drawer with all kinds of odd meds ...</td>\n",
       "      <td>20</td>\n",
       "      <td>do have drawer kinds odd meds found some amoxi...</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            Author ID             Tweet ID Language  \\\n",
       "2         3.0  1030000000000000000  1690000000000000000       en   \n",
       "3         4.0           2245928095  1690000000000000000       en   \n",
       "4         5.0  1590000000000000000  1690000000000000000       en   \n",
       "5         6.0            388774547  1690000000000000000       en   \n",
       "8         9.0            830271474  1690000000000000000       en   \n",
       "\n",
       "                  Created at  \\\n",
       "2  2023-08-21 09:09:19+00:00   \n",
       "3  2023-08-21 09:09:16+00:00   \n",
       "4  2023-08-21 08:47:58+00:00   \n",
       "5  2023-08-21 08:47:22+00:00   \n",
       "8  2023-08-21 05:23:58+00:00   \n",
       "\n",
       "                                                Text Word Count  \\\n",
       "2  @bearish0411 if its COVID, amoxicillin will no...         23   \n",
       "3  @missmulrooney alarm. got it. coincidentally, ...         14   \n",
       "4  RT @skdembe: #BeAntibioticsAware... It's #Anti...         15   \n",
       "5  ''took her straight to drs AGAIN where the doc...         49   \n",
       "8  I do have a drawer with all kinds of odd meds ...         20   \n",
       "\n",
       "                                           New Tweet Word Count.1 Location  \\\n",
       "2  its covid amoxicillin will not work pretty sur...           10      NaN   \n",
       "3  alarm got coincidentally i have just started a...           10      NaN   \n",
       "4  #beantibioticsaware it is #antibioticawareness...            8      NaN   \n",
       "5  took straight drs again where doctor time says...           32      NaN   \n",
       "8  do have drawer kinds odd meds found some amoxi...           13      NaN   \n",
       "\n",
       "  Retweet Count Subjectivity  Polarity  Analysis Results  \n",
       "2             0     0.944444     0.375  Positive       1  \n",
       "3             0            0       0.3  Positive       1  \n",
       "4             1          0.3         1  Positive       1  \n",
       "5             0     0.466667  0.233333  Positive       1  \n",
       "8             0     0.392857  0.059524  Positive       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Drugs.xlsx')\n",
    "\n",
    "# Filter rows with positive sentiment\n",
    "positives = df[df['Analysis'] == 'Positive']\n",
    "positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f7a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    its covid amoxicillin will not work pretty sur...\n",
       "3    alarm got coincidentally i have just started a...\n",
       "4    #beantibioticsaware it is #antibioticawareness...\n",
       "5    took straight drs again where doctor time says...\n",
       "8    do have drawer kinds odd meds found some amoxi...\n",
       "Name: New Tweet, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = positives['New Tweet']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92736498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import en_core_web_sm\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066d09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covid', 'amoxicillin', 'work', 'pretty', 'sure', 'doctor', 'prescribe', 'think', 'covid']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "print(data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6c2f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears \n",
    "# in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a63f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 amoxicillin\n",
      "1 covid\n",
      "2 doctor\n",
      "3 prescribe\n",
      "4 pretty\n",
      "5 sure\n",
      "6 think\n",
      "7 work\n",
      "8 alarm\n",
      "9 coincidentally\n",
      "10 get\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3b55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d825f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 44 (\"med\") appears 1 time.\n",
      "Word 185 (\"addition\") appears 1 time.\n",
      "Word 186 (\"arrive\") appears 1 time.\n",
      "Word 187 (\"baby\") appears 1 time.\n",
      "Word 188 (\"bad\") appears 1 time.\n",
      "Word 189 (\"fur\") appears 1 time.\n",
      "Word 190 (\"gray\") appears 1 time.\n",
      "Word 191 (\"hand\") appears 1 time.\n",
      "Word 192 (\"happy\") appears 1 time.\n",
      "Word 193 (\"hirudoid\") appears 1 time.\n",
      "Word 194 (\"keep\") appears 1 time.\n",
      "Word 195 (\"know\") appears 2 time.\n",
      "Word 196 (\"manage\") appears 1 time.\n",
      "Word 197 (\"mth\") appears 1 time.\n",
      "Word 198 (\"reduce\") appears 1 time.\n",
      "Word 199 (\"savlon\") appears 1 time.\n",
      "Word 200 (\"seizure\") appears 1 time.\n",
      "Word 201 (\"slave\") appears 1 time.\n",
      "Word 202 (\"supply\") appears 1 time.\n",
      "Word 203 (\"swell\") appears 1 time.\n",
      "Word 204 (\"watch\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb2b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"amoxicillin\") appears 1 time.\n",
      "Document 0: Word 1 (\"covid\") appears 2 time.\n",
      "Document 0: Word 2 (\"doctor\") appears 1 time.\n",
      "Document 0: Word 3 (\"prescribe\") appears 1 time.\n",
      "Document 0: Word 4 (\"pretty\") appears 1 time.\n",
      "Document 0: Word 5 (\"sure\") appears 1 time.\n",
      "Document 0: Word 6 (\"think\") appears 1 time.\n",
      "Document 0: Word 7 (\"work\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 8 (\"alarm\") appears 1 time.\n",
      "Document 1: Word 9 (\"coincidentally\") appears 1 time.\n",
      "Document 1: Word 10 (\"get\") appears 1 time.\n",
      "Document 1: Word 11 (\"just\") appears 1 time.\n",
      "Document 1: Word 12 (\"so\") appears 1 time.\n",
      "Document 1: Word 13 (\"start\") appears 1 time.\n",
      "Document 1: Word 14 (\"today\") appears 1 time.\n",
      "Document 1: Word 15 (\"useful\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 0 (\"amoxicillin\") appears 1 time.\n",
      "Document 2: Word 16 (\"antibiotic\") appears 1 time.\n",
      "Document 2: Word 17 (\"good\") appears 1 time.\n",
      "Document 2: Word 18 (\"match\") appears 1 time.\n",
      "Document 2: Word 19 (\"personality\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 0 (\"amoxicillin\") appears 1 time.\n",
      "Document 3: Word 2 (\"doctor\") appears 1 time.\n",
      "Document 3: Word 20 (\"again\") appears 2 time.\n",
      "Document 3: Word 21 (\"chest\") appears 1 time.\n",
      "Document 3: Word 22 (\"definite\") appears 1 time.\n",
      "Document 3: Word 23 (\"drs\") appears 1 time.\n",
      "Document 3: Word 24 (\"give\") appears 1 time.\n",
      "Document 3: Word 25 (\"happen\") appears 1 time.\n",
      "Document 3: Word 26 (\"hear\") appears 1 time.\n",
      "Document 3: Word 27 (\"infection\") appears 1 time.\n",
      "Document 3: Word 28 (\"likely\") appears 1 time.\n",
      "Document 3: Word 29 (\"most\") appears 1 time.\n",
      "Document 3: Word 30 (\"normal\") appears 1 time.\n",
      "Document 3: Word 31 (\"ongoing\") appears 1 time.\n",
      "Document 3: Word 32 (\"pocket\") appears 1 time.\n",
      "Document 3: Word 33 (\"rattle\") appears 1 time.\n",
      "Document 3: Word 34 (\"reply\") appears 1 time.\n",
      "Document 3: Word 35 (\"say\") appears 1 time.\n",
      "Document 3: Word 36 (\"see\") appears 1 time.\n",
      "Document 3: Word 37 (\"straight\") appears 1 time.\n",
      "Document 3: Word 38 (\"take\") appears 2 time.\n",
      "Document 3: Word 39 (\"time\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 0 (\"amoxicillin\") appears 1 time.\n",
      "Document 4: Word 40 (\"drawer\") appears 1 time.\n",
      "Document 4: Word 41 (\"find\") appears 1 time.\n",
      "Document 4: Word 42 (\"hurt\") appears 1 time.\n",
      "Document 4: Word 43 (\"kind\") appears 1 time.\n",
      "Document 4: Word 44 (\"med\") appears 1 time.\n",
      "Document 4: Word 45 (\"odd\") appears 1 time.\n",
      "Document 4: Word 46 (\"right\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 0 (\"amoxicillin\") appears 1 time.\n",
      "Document 5: Word 47 (\"currently\") appears 1 time.\n",
      "Document 5: Word 48 (\"do\") appears 1 time.\n",
      "Document 5: Word 49 (\"exist\") appears 1 time.\n",
      "Document 5: Word 50 (\"gi\") appears 1 time.\n",
      "Document 5: Word 51 (\"issue\") appears 1 time.\n",
      "Document 5: Word 52 (\"more\") appears 1 time.\n",
      "Document 5: Word 53 (\"prepared\") appears 1 time.\n",
      "Document 5: Word 54 (\"stomach\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 6: Word 0 (\"amoxicillin\") appears 1 time.\n",
      "Document 6: Word 1 (\"covid\") appears 1 time.\n",
      "Document 6: Word 2 (\"doctor\") appears 1 time.\n",
      "Document 6: Word 3 (\"prescribe\") appears 2 time.\n",
      "Document 6: Word 7 (\"work\") appears 1 time.\n",
      "Document 6: Word 46 (\"right\") appears 2 time.\n",
      "Document 6: Word 55 (\"actually\") appears 2 time.\n",
      "Document 6: Word 56 (\"fight\") appears 1 time.\n",
      "Document 6: Word 57 (\"go\") appears 1 time.\n",
      "Document 6: Word 58 (\"mean\") appears 1 time.\n",
      "Document 6: Word 59 (\"still\") appears 1 time.\n",
      "Document 6: Word 60 (\"too\") appears 1 time.\n",
      "Document 6: Word 61 (\"treat\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 7: Word 17 (\"good\") appears 1 time.\n",
      "Document 7: Word 62 (\"outcome\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 10 (\"get\") appears 1 time.\n",
      "Document 8: Word 13 (\"start\") appears 1 time.\n",
      "Document 8: Word 14 (\"today\") appears 1 time.\n",
      "Document 8: Word 16 (\"antibiotic\") appears 1 time.\n",
      "Document 8: Word 38 (\"take\") appears 1 time.\n",
      "Document 8: Word 59 (\"still\") appears 1 time.\n",
      "Document 8: Word 63 (\"afternoon\") appears 1 time.\n",
      "Document 8: Word 64 (\"any\") appears 1 time.\n",
      "Document 8: Word 65 (\"appointment\") appears 1 time.\n",
      "Document 8: Word 66 (\"diagnose\") appears 1 time.\n",
      "Document 8: Word 67 (\"enough\") appears 1 time.\n",
      "Document 8: Word 68 (\"feel\") appears 1 time.\n",
      "Document 8: Word 69 (\"hopefully\") appears 1 time.\n",
      "Document 8: Word 70 (\"initially\") appears 1 time.\n",
      "Document 8: Word 71 (\"luckily\") appears 1 time.\n",
      "Document 8: Word 72 (\"morning\") appears 1 time.\n",
      "Document 8: Word 73 (\"np\") appears 1 time.\n",
      "Document 8: Word 74 (\"offer\") appears 1 time.\n",
      "Document 8: Word 75 (\"strong\") appears 1 time.\n",
      "Document 8: Word 76 (\"tomorrow\") appears 1 time.\n",
      "Document 8: Word 77 (\"well\") appears 2 time.\n",
      "\n",
      "\n",
      "Document 9: Word 17 (\"good\") appears 1 time.\n",
      "Document 9: Word 78 (\"adrenaline\") appears 1 time.\n",
      "Document 9: Word 79 (\"capable\") appears 1 time.\n",
      "Document 9: Word 80 (\"carry\") appears 1 time.\n",
      "Document 9: Word 81 (\"chemist\") appears 1 time.\n",
      "Document 9: Word 82 (\"cook\") appears 1 time.\n",
      "Document 9: Word 83 (\"equipment\") appears 1 time.\n",
      "Document 9: Word 84 (\"glue\") appears 1 time.\n",
      "Document 9: Word 85 (\"heroin\") appears 1 time.\n",
      "Document 9: Word 86 (\"home\") appears 1 time.\n",
      "Document 9: Word 87 (\"iodine\") appears 1 time.\n",
      "Document 9: Word 88 (\"isopropyl\") appears 1 time.\n",
      "Document 9: Word 89 (\"kit\") appears 1 time.\n",
      "Document 9: Word 90 (\"make\") appears 1 time.\n",
      "Document 9: Word 91 (\"own\") appears 1 time.\n",
      "Document 9: Word 92 (\"poppy\") appears 1 time.\n",
      "Document 9: Word 93 (\"propylhexedrine\") appears 1 time.\n",
      "Document 9: Word 94 (\"sewing\") appears 1 time.\n",
      "Document 9: Word 95 (\"super\") appears 1 time.\n",
      "Document 9: Word 96 (\"syringe\") appears 1 time.\n",
      "Document 9: Word 97 (\"tourniquet\") appears 1 time.\n",
      "Document 9: Word 98 (\"train\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], dictionary[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3226ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aebbc653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.015*\"lorazepam\" + 0.012*\"amoxicillin\" + 0.012*\"drug\" + 0.008*\"take\" + 0.008*\"give\" + 0.008*\"first\" + 0.006*\"medicine\" + 0.006*\"flavor\" + 0.006*\"throat\" + 0.006*\"think\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.021*\"lorazepam\" + 0.013*\"get\" + 0.011*\"know\" + 0.011*\"go\" + 0.010*\"more\" + 0.009*\"amoxicillin\" + 0.009*\"so\" + 0.009*\"week\" + 0.009*\"dosage\" + 0.008*\"drug\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.029*\"amoxicillin\" + 0.022*\"get\" + 0.014*\"give\" + 0.012*\"right\" + 0.012*\"lorazepam\" + 0.010*\"too\" + 0.009*\"day\" + 0.009*\"pill\" + 0.009*\"so\" + 0.008*\"say\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.031*\"lorazepam\" + 0.019*\"work\" + 0.015*\"take\" + 0.014*\"help\" + 0.012*\"really\" + 0.012*\"use\" + 0.011*\"make\" + 0.010*\"good\" + 0.010*\"amoxicillin\" + 0.009*\"year\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.020*\"take\" + 0.013*\"amoxicillin\" + 0.013*\"lorazepam\" + 0.012*\"go\" + 0.010*\"get\" + 0.010*\"prescribe\" + 0.010*\"well\" + 0.008*\"make\" + 0.007*\"more\" + 0.007*\"use\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392d1a6",
   "metadata": {},
   "source": [
    "### Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc76d15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>New Tweet</th>\n",
       "      <th>Word Count.1</th>\n",
       "      <th>Location</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1480000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 07:40:46+00:00</td>\n",
       "      <td>Oh but Im allergic to amoxicillin</td>\n",
       "      <td>6</td>\n",
       "      <td>but im allergic amoxicillin</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1130000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 06:53:13+00:00</td>\n",
       "      <td>I thought I was weird for liking Amoxicillin t...</td>\n",
       "      <td>23</td>\n",
       "      <td>thought weird liking amoxicillin taste but see...</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1580000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 04:41:05+00:00</td>\n",
       "      <td>@LouDobbs @drpaulmarik1 You trump cult fools....</td>\n",
       "      <td>43</td>\n",
       "      <td>trump cult fools pushed hydroxy ivermectin ant...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>22717621</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 01:58:31+00:00</td>\n",
       "      <td>Medical things Ive learned I am allergic to in...</td>\n",
       "      <td>27</td>\n",
       "      <td>medical things ive learned allergic last 2 yea...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>94802940</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-20 18:43:51+00:00</td>\n",
       "      <td>@anujtiwari11 Cefexime in amoxicillin right? H...</td>\n",
       "      <td>23</td>\n",
       "      <td>cefexime amoxicillin right? have taken fever p...</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>-0.007143</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0            Author ID             Tweet ID Language  \\\n",
       "6          7.0  1480000000000000000  1690000000000000000       en   \n",
       "7          8.0  1130000000000000000  1690000000000000000       en   \n",
       "9         10.0  1580000000000000000  1690000000000000000       en   \n",
       "14        15.0             22717621  1690000000000000000       en   \n",
       "20        21.0             94802940  1690000000000000000       en   \n",
       "\n",
       "                   Created at  \\\n",
       "6   2023-08-21 07:40:46+00:00   \n",
       "7   2023-08-21 06:53:13+00:00   \n",
       "9   2023-08-21 04:41:05+00:00   \n",
       "14  2023-08-21 01:58:31+00:00   \n",
       "20  2023-08-20 18:43:51+00:00   \n",
       "\n",
       "                                                 Text Word Count  \\\n",
       "6                   Oh but Im allergic to amoxicillin          6   \n",
       "7   I thought I was weird for liking Amoxicillin t...         23   \n",
       "9    @LouDobbs @drpaulmarik1 You trump cult fools....         43   \n",
       "14  Medical things Ive learned I am allergic to in...         27   \n",
       "20  @anujtiwari11 Cefexime in amoxicillin right? H...         23   \n",
       "\n",
       "                                            New Tweet Word Count.1 Location  \\\n",
       "6                         but im allergic amoxicillin            4      NaN   \n",
       "7   thought weird liking amoxicillin taste but see...           15      NaN   \n",
       "9   trump cult fools pushed hydroxy ivermectin ant...           30      NaN   \n",
       "14  medical things ive learned allergic last 2 yea...           16      NaN   \n",
       "20  cefexime amoxicillin right? have taken fever p...           13      NaN   \n",
       "\n",
       "   Retweet Count Subjectivity  Polarity  Analysis Results  \n",
       "6              0            0         0  Negative      -1  \n",
       "7              0        0.625 -0.041667  Negative      -1  \n",
       "9              1         0.42     -0.07  Negative      -1  \n",
       "14             0     0.188889   -0.0625  Negative      -1  \n",
       "20             0     0.567857 -0.007143  Negative      -1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with negative sentiment\n",
    "negatives = df[df['Analysis'] == 'Negative']\n",
    "negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4dda64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6                           but im allergic amoxicillin\n",
       "7     thought weird liking amoxicillin taste but see...\n",
       "9     trump cult fools pushed hydroxy ivermectin ant...\n",
       "14    medical things ive learned allergic last 2 yea...\n",
       "20    cefexime amoxicillin right? have taken fever p...\n",
       "Name: New Tweet, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = negatives['New Tweet']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c197a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import en_core_web_sm\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45f2a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allergic', 'amoxicillin']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "print(data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f7bd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears \n",
    "# in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07fe2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 allergic\n",
      "1 amoxicillin\n",
      "2 antibiotic\n",
      "3 indeed\n",
      "4 like\n",
      "5 other\n",
      "6 seem\n",
      "7 taste\n",
      "8 think\n",
      "9 weird\n",
      "10 well\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9444a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0009d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1 (\"amoxicillin\") appears 1 time.\n",
      "Word 21 (\"infection\") appears 1 time.\n",
      "Word 50 (\"take\") appears 1 time.\n",
      "Word 60 (\"prescription\") appears 1 time.\n",
      "Word 88 (\"sick\") appears 1 time.\n",
      "Word 117 (\"never\") appears 1 time.\n",
      "Word 188 (\"decide\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1777645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"allergic\") appears 1 time.\n",
      "Document 0: Word 1 (\"amoxicillin\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 2 (\"antibiotic\") appears 1 time.\n",
      "Document 1: Word 3 (\"indeed\") appears 1 time.\n",
      "Document 1: Word 4 (\"like\") appears 1 time.\n",
      "Document 1: Word 5 (\"other\") appears 1 time.\n",
      "Document 1: Word 6 (\"seem\") appears 1 time.\n",
      "Document 1: Word 7 (\"taste\") appears 2 time.\n",
      "Document 1: Word 8 (\"think\") appears 1 time.\n",
      "Document 1: Word 9 (\"weird\") appears 1 time.\n",
      "Document 1: Word 10 (\"well\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 11 (\"anti\") appears 1 time.\n",
      "Document 2: Word 12 (\"budesinine\") appears 1 time.\n",
      "Document 2: Word 13 (\"corticosteroid\") appears 1 time.\n",
      "Document 2: Word 14 (\"cult\") appears 1 time.\n",
      "Document 2: Word 15 (\"curceritin\") appears 1 time.\n",
      "Document 2: Word 16 (\"dose\") appears 1 time.\n",
      "Document 2: Word 17 (\"fool\") appears 1 time.\n",
      "Document 2: Word 18 (\"high\") appears 1 time.\n",
      "Document 2: Word 19 (\"hundred\") appears 1 time.\n",
      "Document 2: Word 20 (\"hydroxy\") appears 1 time.\n",
      "Document 2: Word 21 (\"infection\") appears 1 time.\n",
      "Document 2: Word 22 (\"inflammatory\") appears 1 time.\n",
      "Document 2: Word 23 (\"lung\") appears 1 time.\n",
      "Document 2: Word 24 (\"protocol\") appears 1 time.\n",
      "Document 2: Word 25 (\"push\") appears 1 time.\n",
      "Document 2: Word 26 (\"save\") appears 1 time.\n",
      "Document 2: Word 27 (\"secondary\") appears 1 time.\n",
      "Document 2: Word 28 (\"trump\") appears 1 time.\n",
      "Document 2: Word 29 (\"zinc\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 0 (\"allergic\") appears 1 time.\n",
      "Document 3: Word 30 (\"adhesive\") appears 1 time.\n",
      "Document 3: Word 31 (\"ekg\") appears 1 time.\n",
      "Document 3: Word 32 (\"last\") appears 1 time.\n",
      "Document 3: Word 33 (\"learn\") appears 1 time.\n",
      "Document 3: Word 34 (\"little\") appears 1 time.\n",
      "Document 3: Word 35 (\"medical\") appears 1 time.\n",
      "Document 3: Word 36 (\"patch\") appears 1 time.\n",
      "Document 3: Word 37 (\"put\") appears 1 time.\n",
      "Document 3: Word 38 (\"thing\") appears 1 time.\n",
      "Document 3: Word 39 (\"use\") appears 1 time.\n",
      "Document 3: Word 40 (\"ve\") appears 1 time.\n",
      "Document 3: Word 41 (\"year\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 42 (\"cefexime\") appears 1 time.\n",
      "Document 4: Word 43 (\"doctor\") appears 1 time.\n",
      "Document 4: Word 44 (\"fever\") appears 1 time.\n",
      "Document 4: Word 45 (\"get\") appears 1 time.\n",
      "Document 4: Word 46 (\"late\") appears 1 time.\n",
      "Document 4: Word 47 (\"prescribed\") appears 1 time.\n",
      "Document 4: Word 48 (\"relief\") appears 1 time.\n",
      "Document 4: Word 49 (\"right\") appears 1 time.\n",
      "Document 4: Word 50 (\"take\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 2 (\"antibiotic\") appears 1 time.\n",
      "Document 5: Word 21 (\"infection\") appears 1 time.\n",
      "Document 5: Word 39 (\"use\") appears 1 time.\n",
      "Document 5: Word 45 (\"get\") appears 1 time.\n",
      "Document 5: Word 51 (\"ago\") appears 1 time.\n",
      "Document 5: Word 52 (\"available\") appears 1 time.\n",
      "Document 5: Word 53 (\"bottle\") appears 1 time.\n",
      "Document 5: Word 54 (\"cold\") appears 1 time.\n",
      "Document 5: Word 55 (\"medicine\") appears 1 time.\n",
      "Document 5: Word 56 (\"month\") appears 1 time.\n",
      "Document 5: Word 57 (\"need\") appears 1 time.\n",
      "Document 5: Word 58 (\"only\") appears 1 time.\n",
      "Document 5: Word 59 (\"prescribe\") appears 1 time.\n",
      "Document 5: Word 60 (\"prescription\") appears 1 time.\n",
      "Document 5: Word 61 (\"regular\") appears 1 time.\n",
      "Document 5: Word 62 (\"rid\") appears 1 time.\n",
      "Document 5: Word 63 (\"several\") appears 1 time.\n",
      "Document 5: Word 64 (\"sinus\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 6: Word 2 (\"antibiotic\") appears 1 time.\n",
      "Document 6: Word 21 (\"infection\") appears 1 time.\n",
      "Document 6: Word 39 (\"use\") appears 1 time.\n",
      "Document 6: Word 65 (\"acid\") appears 1 time.\n",
      "Document 6: Word 66 (\"active\") appears 1 time.\n",
      "Document 6: Word 67 (\"bacterial\") appears 1 time.\n",
      "Document 6: Word 68 (\"ingredient\") appears 1 time.\n",
      "Document 6: Word 69 (\"pom\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 7: Word 1 (\"amoxicillin\") appears 1 time.\n",
      "Document 7: Word 2 (\"antibiotic\") appears 1 time.\n",
      "Document 7: Word 5 (\"other\") appears 1 time.\n",
      "Document 7: Word 45 (\"get\") appears 1 time.\n",
      "Document 7: Word 60 (\"prescription\") appears 1 time.\n",
      "Document 7: Word 70 (\"always\") appears 1 time.\n",
      "Document 7: Word 71 (\"bellman\") appears 1 time.\n",
      "Document 7: Word 72 (\"buy\") appears 1 time.\n",
      "Document 7: Word 73 (\"couple\") appears 1 time.\n",
      "Document 7: Word 74 (\"course\") appears 1 time.\n",
      "Document 7: Word 75 (\"drug\") appears 1 time.\n",
      "Document 7: Word 76 (\"go\") appears 1 time.\n",
      "Document 7: Word 77 (\"helpful\") appears 1 time.\n",
      "Document 7: Word 78 (\"hotel\") appears 1 time.\n",
      "Document 7: Word 79 (\"lot\") appears 1 time.\n",
      "Document 7: Word 80 (\"spare\") appears 1 time.\n",
      "Document 7: Word 81 (\"travel\") appears 1 time.\n",
      "Document 7: Word 82 (\"usually\") appears 1 time.\n",
      "Document 7: Word 83 (\"way\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 1 (\"amoxicillin\") appears 1 time.\n",
      "Document 8: Word 84 (\"bad\") appears 1 time.\n",
      "Document 8: Word 85 (\"feel\") appears 2 time.\n",
      "Document 8: Word 86 (\"make\") appears 1 time.\n",
      "Document 8: Word 87 (\"omfg\") appears 1 time.\n",
      "Document 8: Word 88 (\"sick\") appears 1 time.\n",
      "Document 8: Word 89 (\"so\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 9: Word 90 (\"past\") appears 1 time.\n",
      "Document 9: Word 91 (\"wonder\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], dictionary[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65e607d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c5dc951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.024*\"get\" + 0.022*\"amoxicillin\" + 0.014*\"so\" + 0.012*\"help\" + 0.011*\"go\" + 0.010*\"bad\" + 0.008*\"doctor\" + 0.008*\"still\" + 0.008*\"give\" + 0.008*\"little\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.018*\"amoxicillin\" + 0.016*\"take\" + 0.014*\"use\" + 0.013*\"lorazepam\" + 0.010*\"go\" + 0.008*\"get\" + 0.008*\"allergic\" + 0.008*\"infection\" + 0.008*\"time\" + 0.008*\"only\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.019*\"infection\" + 0.014*\"antibiotic\" + 0.011*\"day\" + 0.011*\"amoxicillin\" + 0.008*\"buy\" + 0.008*\"give\" + 0.008*\"doctor\" + 0.008*\"ear\" + 0.008*\"say\" + 0.006*\"covid\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.029*\"lorazepam\" + 0.027*\"take\" + 0.021*\"cancer\" + 0.015*\"pancreatic\" + 0.011*\"outcome\" + 0.010*\"work\" + 0.010*\"patient\" + 0.010*\"treatment\" + 0.009*\"go\" + 0.009*\"say\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.017*\"lorazepam\" + 0.012*\"get\" + 0.012*\"antibiotic\" + 0.010*\"just\" + 0.010*\"other\" + 0.010*\"so\" + 0.008*\"bad\" + 0.008*\"use\" + 0.007*\"think\" + 0.007*\"end\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af284dd9",
   "metadata": {},
   "source": [
    "### Neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f90d22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>New Tweet</th>\n",
       "      <th>Word Count.1</th>\n",
       "      <th>Location</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>599628533</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 10:26:24+00:00</td>\n",
       "      <td>RT @theliamnissan: Lauren Boebert calling for ...</td>\n",
       "      <td>21</td>\n",
       "      <td>lauren boebert calling abolishment dept educat...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1090000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 09:14:02+00:00</td>\n",
       "      <td>@amerix I wish I had read seen post last week,...</td>\n",
       "      <td>26</td>\n",
       "      <td>wish had read seen post last week bought ascor...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>877000000000000000</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 02:01:00+00:00</td>\n",
       "      <td>@Phil_Lewis_ Gonna be on a 90 day treatment of...</td>\n",
       "      <td>9</td>\n",
       "      <td>gonna 90 day treatment amoxicillin</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>359191827</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-21 01:13:38+00:00</td>\n",
       "      <td>Me vs amoxicillin \\nMeriang ðŸ‘</td>\n",
       "      <td>4</td>\n",
       "      <td>me vs amoxicillin</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2844157329</td>\n",
       "      <td>1690000000000000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2023-08-20 23:48:05+00:00</td>\n",
       "      <td>amoxicillin is a god-like antibiotic... been d...</td>\n",
       "      <td>15</td>\n",
       "      <td>amoxicillin god-like antibiotic been dealing d...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0            Author ID             Tweet ID Language  \\\n",
       "0          1.0            599628533  1690000000000000000       en   \n",
       "1          2.0  1090000000000000000  1690000000000000000       en   \n",
       "13        14.0   877000000000000000  1690000000000000000       en   \n",
       "15        16.0            359191827  1690000000000000000       en   \n",
       "16        17.0           2844157329  1690000000000000000       en   \n",
       "\n",
       "                   Created at  \\\n",
       "0   2023-08-21 10:26:24+00:00   \n",
       "1   2023-08-21 09:14:02+00:00   \n",
       "13  2023-08-21 02:01:00+00:00   \n",
       "15  2023-08-21 01:13:38+00:00   \n",
       "16  2023-08-20 23:48:05+00:00   \n",
       "\n",
       "                                                 Text Word Count  \\\n",
       "0   RT @theliamnissan: Lauren Boebert calling for ...         21   \n",
       "1   @amerix I wish I had read seen post last week,...         26   \n",
       "13  @Phil_Lewis_ Gonna be on a 90 day treatment of...          9   \n",
       "15                   Me vs amoxicillin \\nMeriang ðŸ‘          4   \n",
       "16  amoxicillin is a god-like antibiotic... been d...         15   \n",
       "\n",
       "                                            New Tweet Word Count.1 Location  \\\n",
       "0   lauren boebert calling abolishment dept educat...           12      NaN   \n",
       "1   wish had read seen post last week bought ascor...           19      NaN   \n",
       "13                 gonna 90 day treatment amoxicillin            5      NaN   \n",
       "15                                 me vs amoxicillin             3      NaN   \n",
       "16  amoxicillin god-like antibiotic been dealing d...           10      NaN   \n",
       "\n",
       "   Retweet Count Subjectivity Polarity Analysis Results  \n",
       "0           3560            0        0  Neutral       0  \n",
       "1              0     0.066667        0  Neutral       0  \n",
       "13             0            0        0  Neutral       0  \n",
       "15             0            0        0  Neutral       0  \n",
       "16             0            0        0  Neutral       0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with neutral sentiment\n",
    "neutrals = df[df['Analysis'] == 'Neutral']\n",
    "neutrals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bad5c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     lauren boebert calling abolishment dept educat...\n",
       "1     wish had read seen post last week bought ascor...\n",
       "13                   gonna 90 day treatment amoxicillin\n",
       "15                                   me vs amoxicillin \n",
       "16    amoxicillin god-like antibiotic been dealing d...\n",
       "Name: New Tweet, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = neutrals['New Tweet']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07860a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import en_core_web_sm\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    " # Handle NaN values\n",
    "        if pd.isna(text):\n",
    "            text = ''\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = ' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e423e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'dept', 'education', 'chlamydia', 'speak', 'danger']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "print(data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23380593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the number of times a word appears \n",
    "# in the training set using gensim.corpora.Dictionary and call it dictionary\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93962389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 call\n",
      "1 chlamydia\n",
      "2 danger\n",
      "3 dept\n",
      "4 education\n",
      "5 speak\n",
      "6 always\n",
      "7 amoxiclave\n",
      "8 ascorbic\n",
      "9 buy\n",
      "10 cough\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2880a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8847636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Word 52 (\"get\") appears 1 time.\n",
      "Word 73 (\"function\") appears 1 time.\n",
      "Word 74 (\"know\") appears 1 time.\n",
      "Word 75 (\"pull\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed document\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97b8a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Word 0 (\"call\") appears 1 time.\n",
      "Document 0: Word 1 (\"chlamydia\") appears 1 time.\n",
      "Document 0: Word 2 (\"danger\") appears 1 time.\n",
      "Document 0: Word 3 (\"dept\") appears 1 time.\n",
      "Document 0: Word 4 (\"education\") appears 1 time.\n",
      "Document 0: Word 5 (\"speak\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 1: Word 6 (\"always\") appears 1 time.\n",
      "Document 1: Word 7 (\"amoxiclave\") appears 1 time.\n",
      "Document 1: Word 8 (\"ascorbic\") appears 1 time.\n",
      "Document 1: Word 9 (\"buy\") appears 1 time.\n",
      "Document 1: Word 10 (\"cough\") appears 1 time.\n",
      "Document 1: Word 11 (\"last\") appears 1 time.\n",
      "Document 1: Word 12 (\"post\") appears 1 time.\n",
      "Document 1: Word 13 (\"read\") appears 1 time.\n",
      "Document 1: Word 14 (\"see\") appears 1 time.\n",
      "Document 1: Word 15 (\"syrup\") appears 1 time.\n",
      "Document 1: Word 16 (\"time\") appears 1 time.\n",
      "Document 1: Word 17 (\"week\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 2: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 2: Word 19 (\"day\") appears 1 time.\n",
      "Document 2: Word 20 (\"go\") appears 1 time.\n",
      "Document 2: Word 21 (\"treatment\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 3: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 4: Word 22 (\"antibiotic\") appears 1 time.\n",
      "Document 4: Word 23 (\"be\") appears 1 time.\n",
      "Document 4: Word 24 (\"deal\") appears 1 time.\n",
      "Document 4: Word 25 (\"double\") appears 1 time.\n",
      "Document 4: Word 26 (\"ear\") appears 1 time.\n",
      "Document 4: Word 27 (\"infection\") appears 2 time.\n",
      "Document 4: Word 28 (\"like\") appears 1 time.\n",
      "Document 4: Word 29 (\"sinus\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 5: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "Document 5: Word 30 (\"allergic\") appears 1 time.\n",
      "Document 5: Word 31 (\"find\") appears 1 time.\n",
      "Document 5: Word 32 (\"imagine\") appears 1 time.\n",
      "Document 5: Word 33 (\"look\") appears 1 time.\n",
      "Document 5: Word 34 (\"need\") appears 1 time.\n",
      "Document 5: Word 35 (\"now\") appears 1 time.\n",
      "Document 5: Word 36 (\"surprise\") appears 1 time.\n",
      "Document 5: Word 37 (\"take\") appears 1 time.\n",
      "Document 5: Word 38 (\"year\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 6: Word 39 (\"covid\") appears 1 time.\n",
      "Document 6: Word 40 (\"give\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 7: Word 18 (\"amoxicillin\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 8: Word 41 (\"druggie\") appears 1 time.\n",
      "Document 8: Word 42 (\"here\") appears 1 time.\n",
      "\n",
      "\n",
      "Document 9: Word 26 (\"ear\") appears 1 time.\n",
      "Document 9: Word 27 (\"infection\") appears 1 time.\n",
      "Document 9: Word 40 (\"give\") appears 1 time.\n",
      "Document 9: Word 43 (\"baby\") appears 1 time.\n",
      "Document 9: Word 44 (\"insomniac\") appears 1 time.\n",
      "Document 9: Word 45 (\"night\") appears 1 time.\n",
      "Document 9: Word 46 (\"realize\") appears 1 time.\n",
      "Document 9: Word 47 (\"th\") appears 1 time.\n",
      "Document 9: Word 48 (\"turn\") appears 1 time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore other documents in your corpus\n",
    "for document_num in range(10):  # Print information for the first 10 documents\n",
    "    bow_doc_x = bow_corpus[document_num]\n",
    "    for i in range(len(bow_doc_x)):\n",
    "        print(\"Document {}: Word {} (\\\"{}\\\") appears {} time.\".format(\n",
    "            document_num, bow_doc_x[i][0], dictionary[bow_doc_x[i][0]], bow_doc_x[i][1]\n",
    "        ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4837e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5,\n",
    "                                   random_state=46,\n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2aa21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.058*\"take\" + 0.033*\"amoxicillin\" + 0.029*\"lorazepam\" + 0.016*\"patient\" + 0.016*\"know\" + 0.014*\"say\" + 0.014*\"allergic\" + 0.010*\"now\" + 0.010*\"short\" + 0.010*\"survival\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.068*\"amoxicillin\" + 0.044*\"lorazepam\" + 0.014*\"get\" + 0.014*\"day\" + 0.011*\"time\" + 0.011*\"sleep\" + 0.011*\"use\" + 0.007*\"need\" + 0.007*\"include\" + 0.007*\"die\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.034*\"lorazepam\" + 0.031*\"give\" + 0.022*\"need\" + 0.010*\"amoxicillin\" + 0.010*\"buy\" + 0.010*\"antibiotic\" + 0.010*\"go\" + 0.007*\"metronidazole\" + 0.007*\"also\" + 0.007*\"work\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.027*\"get\" + 0.017*\"amoxicillin\" + 0.014*\"infection\" + 0.014*\"start\" + 0.011*\"lorazepam\" + 0.011*\"take\" + 0.011*\"stop\" + 0.011*\"use\" + 0.011*\"antibiotic\" + 0.011*\"today\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.035*\"lorazepam\" + 0.022*\"amoxicillin\" + 0.018*\"use\" + 0.009*\"cause\" + 0.009*\"infection\" + 0.009*\"doctor\" + 0.009*\"user\" + 0.009*\"psychosis\" + 0.009*\"see\" + 0.009*\"dream\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc0c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
